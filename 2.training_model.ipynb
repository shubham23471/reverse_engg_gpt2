{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# simplest data to work with : tiny shakespare \n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "data = text[:1000]\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5962, 22307, 25, 198, 8421, 356, 5120, 597, 2252, 11, 3285, 502, 2740, 13, 198, 198, 3237, 25, 198, 5248, 461, 11, 2740, 13, 198, 198, 5962, 22307, 25, 198, 1639, 389, 477, 12939, 2138, 284, 4656, 621, 284, 1145, 680, 30, 198, 198, 3237, 25, 198, 4965, 5634, 13, 12939, 13, 198, 198, 5962, 22307, 25, 198, 5962, 11, 345, 760, 327, 1872, 385, 1526, 28599, 318, 4039, 4472, 284, 262, 661, 13, 198, 198, 3237, 25, 198, 1135, 760, 470, 11, 356, 760, 470, 13, 198, 198, 5962, 22307, 25, 198, 5756, 514, 1494, 683, 11, 290, 356, 1183, 423, 11676, 379, 674, 898, 2756, 13, 198, 3792, 470, 257, 15593, 30, 198, 198, 3237, 25, 198, 2949, 517, 3375, 319, 470, 26, 1309, 340, 307, 1760, 25, 1497, 11, 1497, 0, 198, 198, 12211, 22307, 25, 198, 3198, 1573, 11, 922, 4290, 13, 198, 198, 5962, 22307, 25, 198, 1135, 389, 17830, 3595, 4290, 11, 262, 1458, 1173, 1547, 922, 13, 198, 2061, 4934, 969, 5036, 896, 319, 561, 26958, 514, 25, 611, 484, 198, 19188, 7800, 514, 475, 262, 48713, 414, 11, 981, 340, 547, 198, 1929, 4316, 462, 11, 356, 1244, 4724, 484, 22598, 514, 31533, 306, 26, 198, 4360, 484, 892, 356, 389, 1165, 13674, 25, 262, 10904, 1108, 326, 198, 2001, 42267, 514, 11, 262, 2134, 286, 674, 24672, 11, 318, 355, 281, 198, 24807, 284, 1948, 786, 511, 20038, 26, 674, 198, 82, 13712, 590, 318, 257, 4461, 284, 606, 3914, 514, 15827, 428, 351, 198, 454, 279, 7938, 11, 304, 260, 356, 1716, 374, 1124, 25, 329, 262, 11858, 760, 314, 198, 47350, 428, 287, 16460, 329, 8509, 11, 407, 287, 24613, 329, 15827, 13, 628]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(data)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5962, 22307,    25,   198,  8421,   356],\n",
       "        [ 5120,   597,  2252,    11,  3285,   502],\n",
       "        [ 2740,    13,   198,   198,  3237,    25],\n",
       "        [  198,  5248,   461,    11,  2740,    13]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to take these tokens and forward them in our GPT model \n",
    "# to do that we have reshape our long list of token sequence into a (B, T) tensor \n",
    "# before that tha shape our forward function takes\n",
    "# take an example of 24 tokens to understand this\n",
    "\n",
    "import torch\n",
    "buf = torch.tensor(tokens[:24])\n",
    "x = buf.view(4, 6)\n",
    "x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, that's our input to the transformer. Now, we also need labels to calucate the loss function. \n",
    "- For this we can write some code in the forward pass of the GPT model, as we know the next sequence is just the right of us. But the problem with that approch is that the for the token 13 (the last toke) we don't have the label information. \n",
    "- So Andrej fav way to do this, is that we will create the another tensor label of exact same size as x but it contains the labels at every position. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5962, 22307,    25,   198,  8421,   356],\n",
       "         [ 5120,   597,  2252,    11,  3285,   502],\n",
       "         [ 2740,    13,   198,   198,  3237,    25],\n",
       "         [  198,  5248,   461,    11,  2740,    13]]),\n",
       " tensor([[22307,    25,   198,  8421,   356,  5120],\n",
       "         [  597,  2252,    11,  3285,   502,  2740],\n",
       "         [   13,   198,   198,  3237,    25,   198],\n",
       "         [ 5248,   461,    11,  2740,    13,   198]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so, in the buf we get the last token + 1 and then index our x and y \n",
    "buf = torch.tensor(tokens[:24 + 1 ])\n",
    "x = buf[:-1].view(4, 6) \n",
    "y = buf[1:].view(4, 6) \n",
    "x, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we go back to our script and create a very simpel dataloader object to load these tokens, feed them to transformer and calculate the loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- \n",
    "\n",
    "Now, we want to calculate the loss function and to do so we have to modify the forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using device: cuda\n",
    "Only loading first 1k charchters as model input\n",
    "logits shape torch.Size([4, 32, 50257])\n",
    "loss tensor(11.0371, device='cuda:0', grad_fn=<NllLossBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9897725689953638e-05, -10.82490511970208)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "1/ 50257, -math.log(50257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
